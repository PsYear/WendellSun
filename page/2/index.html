<!DOCTYPE html>
<html lang="">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 3.9.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-wendellsun.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/wendellsun_32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/wendellsun_16x16.png.png">
  <link rel="mask-icon" href="/images/wendellsun_logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('https://www.wendellsun.com').hostname,
    root: '/',
    scheme: 'Muse',
    version: '7.6.0',
    exturl: false,
    sidebar: {"position":"left","display":"remove","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    comments: {"style":"tabs","active":"gitalk","storage":true,"lazyload":false,"nav":{"gitalk":{"order":-2}},"activeClass":"gitalk"},
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":3,"unescape":false,"preload":false},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}
  };
</script>

  <meta property="og:type" content="website">
<meta property="og:title" content="宋竹温 | 不羁跬步">
<meta property="og:url" content="https://www.wendellsun.com/page/2/index.html">
<meta property="og:site_name" content="宋竹温 | 不羁跬步">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="宋竹温 | 不羁跬步">

<link rel="canonical" href="https://www.wendellsun.com/page/2/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: true,
    isPost: false
  };
</script>

  <title>宋竹温 | 不羁跬步</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="stylesheet" href="/assets/css/APlayer.min.css" class="aplayer-style-marker">
<script src="/assets/js/APlayer.min.js" class="aplayer-script-marker"></script>
<script src="/assets/js/Meting.min.js" class="meting-script-marker"></script>
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">宋竹温 | 不羁跬步</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">工人有力量，硅器有生命</p>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-rss">

    <a href="/rss2.xml" rel="section"><i class="fa fa-fw fa-rss"></i>Rss</a>

  </li>
        <li class="menu-item menu-item-router">

    <a href="/2020/03/31/尝无止尽路由/index.html" rel="section"><i class="fa fa-fw fa-sitemap"></i>Router</a>

  </li>
        <li class="menu-item menu-item-cinema">

    <a href="http://wendellsun.live/" rel="noopener" target="_blank"><i class="fa fa-fw fa-film"></i>Cinema</a>

  </li>
        <li class="menu-item menu-item-castecho">

    <a href="https://www.castecho.com/" rel="noopener" target="_blank"><i class="fa fa-fw fa-bullseye"></i>CastEcho</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="Searching..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="default">
    <link itemprop="mainEntityOfPage" href="https://www.wendellsun.com/2019/07/02/「The-score」意外小众的流行摇滚组合/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Wendell Sun">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="宋竹温 | 不羁跬步">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2019/07/02/「The-score」意外小众的流行摇滚组合/" class="post-title-link" itemprop="url">「The score」意外小众的流行摇滚组合</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-07-02 13:49:17" itemprop="dateCreated datePublished" datetime="2019-07-02T13:49:17+08:00">2019-07-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-12-24 19:43:36" itemprop="dateModified" datetime="2019-12-24T19:43:36+08:00">2019-12-24</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          
    <div id="aplayer-uzSuMxzP" class="aplayer aplayer-tag-marker meting-tag-marker" data-id="471411253" data-server="netease" data-type="song" data-mode="circulation" data-autoplay="false" data-mutex="true" data-listmaxheight="340px" data-preload="auto" data-theme="#FF4081"></div>


<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference:"></a>Reference:</h3><p><a href="https://github.com/metowolf/MetingJS#option" target="_blank" rel="noopener">MetingJS</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="default">
    <link itemprop="mainEntityOfPage" href="https://www.wendellsun.com/2018/11/23/Bert-FineTune-实践/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Wendell Sun">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="宋竹温 | 不羁跬步">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2018/11/23/Bert-FineTune-实践/" class="post-title-link" itemprop="url">Bert FineTune 实践</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-11-23 00:00:00" itemprop="dateCreated datePublished" datetime="2018-11-23T00:00:00+08:00">2018-11-23</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-12-24 19:43:36" itemprop="dateModified" datetime="2019-12-24T19:43:36+08:00">2019-12-24</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>从11月初开始，<a href="https://github.com/google-research" target="_blank" rel="noopener">google-research</a>就陆续开源了<a href="https://github.com/google-research/bert" target="_blank" rel="noopener">bert</a>的各个版本。google此次开源的bert是通过tensorflow高级API—— <code>tf.estimator</code>进行封装(wrapper)的。因此对于不同数据集的适配，只需要修改代码中的processor部分，就能进行代码的训练、交叉验证和测试。</p>
<h2 id="在自己的数据集上运行bert"><a href="#在自己的数据集上运行bert" class="headerlink" title="在自己的数据集上运行bert"></a>在自己的数据集上运行bert</h2><p>bert的代码同论文里描述的一致，主要分为两个部分。一个是训练语言模型（language model）的预训练（pretrain）部分。另一个是训练具体任务(task)的fine-tune部分。在开源的代码中，预训练的入口是在<code>run_pretraining.py</code>而fine-tune的入口针对不同的任务分别在<code>run_classifier.py</code>和<code>run_squad.py</code>。其中<code>run_classifier.py</code>适用的任务为分类任务。如CoLA、MRPC、MultiNLI这些数据集。而<code>run_squad.py</code>适用的是阅读理解(MRC)任务，如squad2.0和squad1.1。预训练是bert很重要的一个部分，与此同时，预训练需要巨大的运算资源。按照论文里描述的参数，其Base的设定在消费级的显卡Titan x 或Titan 1080ti(12GB RAM)上，甚至需要近几个月的时间进行预训练，同时还会面临显存不足的问题。不过所幸的是谷歌满足了<a href="https://github.com/google-research/bert/issues/2" target="_blank" rel="noopener">issues#2</a>里各国开发者的请求，针对大部分语言都公布了bert的<a href="https://github.com/google-research/bert/blob/master/multilingual.md" target="_blank" rel="noopener">预训练模型</a>。因此在我们可以比较方便得在自己的数据集上进行fine-tune。</p>
<h3 id="下载预训练模型"><a href="#下载预训练模型" class="headerlink" title="下载预训练模型"></a>下载预训练模型</h3><p>对于中文而言，google公布了一个参数较小的bert预训练模型。具体参数数值如下所示：</p>
<blockquote>
<p>Chinese Simplified and Traditional, 12-layer, 768-hidden, 12-heads, 110M parameters  </p>
</blockquote>
<p>模型的<a href="https://storage.googleapis.com/bert_models/2018_11_03/chinese_L-12_H-768_A-12.zip" target="_blank" rel="noopener">下载链接</a>可以在github上google的开源代码里找到。对下载的压缩文件进行解压，可以看到文件里有五个文件，其中bert_model.ckpt开头的文件是负责模型变量载入的，而vocab.txt是训练时中文文本采用的字典，最后bert_config.json是bert在训练时，可选调整的一些参数。</p>
<h3 id="修改processor"><a href="#修改processor" class="headerlink" title="修改processor"></a>修改processor</h3><p>任何模型的训练、预测都是需要有一个明确的输入，而bert代码中processor就是负责对模型的输入进行处理。我们以分类任务的为例，介绍如何修改processor来运行自己数据集上的fine-tune。在<code>run_classsifier.py</code>文件中我们可以看到，google对于一些公开数据集已经写了一些processor，如<code>XnliProcessor</code>,<code>MnliProcessor</code>,<code>MrpcProcessor</code>和<code>ColaProcessor</code>。这给我们提供了一个很好的示例，指导我们如何针对自己的数据集来写processor。<br>对于一个需要执行训练、交叉验证和测试完整过程的模型而言，自定义的processor里需要继承DataProcessor，并重载获取label的<code>get_labels</code>和获取单个输入的<code>get_train_examples</code>,<code>get_dev_examples</code>和<code>get_test_examples</code>函数。其分别会在<code>main</code>函数的<code>FLAGS.do_train</code>、<code>FLAGS.do_eval</code>和<code>FLAGS.do_predict</code>阶段被调用。<br>这三个函数的内容是相差无几的，区别只在于需要指定各自读入文件的地址。以<code>get_train_examples</code>为例，函数需要返回一个由<code>InputExample</code>类组成的<code>list</code>。<code>InputExample</code>类是一个很简单的类，只有初始化函数，需要传入的参数中guid是用来区分每个example的，可以按照<code>train-%d&#39;%(i)</code>的方式进行定义。text_a是一串字符串，text_b则是另一串字符串。在进行后续输入处理后(bert代码中已包含，不需要自己完成) text_a和text_b将组合成<code>[CLS] text_a [SEP] text_b [SEP]</code>的形式传入模型。最后一个参数label也是字符串的形式，label的内容需要保证出现在<code>get_labels</code>函数返回的<code>list</code>里。<br>举一个例子，假设我们想要处理一个能够判断句子相似度的模型，现在在<code>data_dir</code>的路径下有一个名为<code>train.csv</code>的输入文件，如果我们现在输入文件的格式如下csv形式：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1,你好,您好</span><br><span class="line">0,你好,你家住哪</span><br></pre></td></tr></table></figure>

<p>那么我们可以写一个如下的<code>get_train_examples</code>的函数。当然对于csv的处理，可以使用诸如<code>csv.reader</code>的形式进行读入。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_train_examples</span><span class="params">(self, data_dir)</span>：</span></span><br><span class="line">    file_path = os.path.join(data_dir, 'train.csv')</span><br><span class="line">    <span class="keyword">with</span> open(file_path, <span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        reader = f.readlines()</span><br><span class="line">    examples = []</span><br><span class="line">    <span class="keyword">for</span> index, line <span class="keyword">in</span> enumerate(reader):</span><br><span class="line">        guid = <span class="string">'train-%d'</span>%index</span><br><span class="line">        split_line = line.strip().split(<span class="string">','</span>)</span><br><span class="line">        text_a = tokenization.convert_to_unicode(split_line[<span class="number">1</span>])</span><br><span class="line">        text_b = tokenization.convert_to_unicode(split_line[<span class="number">2</span>])</span><br><span class="line">        label = split_line[<span class="number">0</span>]</span><br><span class="line">        examples.append(InputExample(guid=guid, text_a=text_a,</span><br><span class="line">                                        text_b=text_b, label=label))</span><br><span class="line">    <span class="keyword">return</span> examples</span><br></pre></td></tr></table></figure>

<p>同时对应判断句子相似度这个二分类任务，<code>get_labels</code>函数可以写成如下的形式：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_labels</span><span class="params">(self)</span>:</span></span><br><span class="line">    reutrn [<span class="string">'0'</span>,<span class="string">'1'</span>]</span><br></pre></td></tr></table></figure>

<p>在对<code>get_dev_examples</code>和<code>get_test_examples</code>函数做类似<code>get_train_examples</code>的操作后，便完成了对processor的修改。其中<code>get_test_examples</code>可以传入一个随意的label数值，因为在模型的预测（prediction）中label将不会参与计算。  </p>
<h3 id="修改processor字典"><a href="#修改processor字典" class="headerlink" title="修改processor字典"></a>修改processor字典</h3><p>修改完成processor后，需要在在原本<code>main</code>函数的processor字典里，加入修改后的processor类，即可在运行参数里指定调用该processor。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">processors = &#123;</span><br><span class="line">     <span class="string">"cola"</span>: ColaProcessor,</span><br><span class="line">     <span class="string">"mnli"</span>: MnliProcessor,</span><br><span class="line">     <span class="string">"mrpc"</span>: MrpcProcessor,</span><br><span class="line">     <span class="string">"xnli"</span>: XnliProcessor, </span><br><span class="line">     <span class="string">"selfsim"</span>: SelfProcessor <span class="comment">#添加自己的processor</span></span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>

<h3 id="运行fine-tune"><a href="#运行fine-tune" class="headerlink" title="运行fine-tune"></a>运行fine-tune</h3><p>之后就可以直接运行<code>run_classsifier.py</code>进行模型的训练。在运行时需要制定一些参数，一个较为完整的运行参数如下所示：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> BERT_BASE_DIR=/path/to/bert/chinese_L-12_H-768_A-12 <span class="comment">#全局变量 下载的预训练bert地址</span></span><br><span class="line"><span class="built_in">export</span> MY_DATASET=/path/to/xnli <span class="comment">#全局变量 数据集所在地址</span></span><br><span class="line"></span><br><span class="line">python run_classifier.py \</span><br><span class="line">  --task_name=selfsim \ <span class="comment">#自己添加processor在processors字典里的key名</span></span><br><span class="line">  --do_train=<span class="literal">true</span> \</span><br><span class="line">  --do_eval=<span class="literal">true</span> \</span><br><span class="line">  --dopredict=<span class="literal">true</span> \</span><br><span class="line">  --data_dir=<span class="variable">$MY_DATASET</span> \</span><br><span class="line">  --vocab_file=<span class="variable">$BERT_BASE_DIR</span>/vocab.txt \</span><br><span class="line">  --bert_config_file=<span class="variable">$BERT_BASE_DIR</span>/bert_config.json \</span><br><span class="line">  --init_checkpoint=<span class="variable">$BERT_BASE_DIR</span>/bert_model.ckpt \</span><br><span class="line">  --max_seq_length=128 \ <span class="comment">#模型参数</span></span><br><span class="line">  --train_batch_size=32 \</span><br><span class="line">  --learning_rate=5e-5 \</span><br><span class="line">  --num_train_epochs=2.0 \</span><br><span class="line">  --output_dir=/tmp/selfsim_output/ <span class="comment">#模型输出路径</span></span><br></pre></td></tr></table></figure>

<h2 id="bert源代码里还有什么"><a href="#bert源代码里还有什么" class="headerlink" title="bert源代码里还有什么"></a>bert源代码里还有什么</h2><p>在开始训练我们自己fine-tune的bert后，我们可以再来看看bert代码里除了processor之外的一些部分。<br>我们可以发现，process在得到字符串形式的输入后，在<code>file_based_convert_examples_to_features</code>里先是对字符串长度，加入[CLS]和[SEP]等一些处理后，将其写入成TFrecord的形式。这是为了能在estimator里有一个更为高效和简易的读入。<br>我们还可以发现，在<code>create_model</code>的函数里，除了从<code>modeling.py</code>获取模型主干输出之外，还有进行fine-tune时候的loss计算。因此，如果对于fine-tune的结构有自定义的要求，可以在这部分对代码进行修改。如进行NER任务的时候，可以按照bert论文里的方式，不只读第一位的logits，而是将每一位logits进行读取。<br>bert这次开源的代码，由于是考虑在google自己的TPU上高效地运行，因此采用的estimator是<code>tf.contrib.tpu.TPUEstimator</code>,虽然tpu的estimator同样可以在gpu和cpu上运行，但若想在gpu上更高效得做一些提升，可以考虑将其换成<code>tf.estimator.Estimator</code>,于此同时model_fn里一些<code>tf.contrib.tpu.TPUEstimatorSpec</code>也需要修改成<code>tf.estimator.EstimatorSpec</code>的形式，以及相关调用参数也需要做一些调整。在转换成较普通的estimator后便可以使用常用的方式对estimator进行处理，如生成用于部署的<code>.pb</code>文件等。</p>
<h2 id="issues里一些有趣的内容"><a href="#issues里一些有趣的内容" class="headerlink" title="issues里一些有趣的内容"></a>issues里一些有趣的内容</h2><p>从google对bert进行开源开始，issues里的讨论便异常活跃，bert论文第一作者javob devlin也积极地在issues里进行回应，在交流讨论中，产生了一些很有趣的内容。<br>在<a href="https://github.com/google-research/bert/issues/95" target="_blank" rel="noopener">#95</a>中大家讨论了bert模型在今年ai-challenger比赛上的应用。我们也同样尝试了bert在ai-challenger的mrc赛道的表现。如果简单得地将mrc的文本连接成一个长字符串的形式，可以在dev集上得到79.1%的准确率。如果参考openAI的GPT<a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf" target="_blank" rel="noopener">论文</a>里multi-choice的形式对bert的输入输出代码进行修改则可以将准确率提高到79.3%。采用的参数都是bert默认的参数，而单一模型成绩在赛道的test a排名中已经能超过榜单上的第一名。因此，在相关中文的任务中，bert能有很大的想象空间。<br>在<a href="https://github.com/google-research/bert/issues/123" target="_blank" rel="noopener">#123</a>中，<a href="https://github.com/hanxiao" target="_blank" rel="noopener">@hanxiao</a>给出了一个采用ZeroMQ便捷部署bert的service，可以直接调用训练好的模型作为应用的接口。同时他将bert改为一个大的encode模型，将文本通过bert进行encode，来实现句子级的encode。此外，他对比了多GPU上的性能，发现bert在多GPU并行上的出色表现。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>总得来说，google此次开源的bert和其预训练模型是非常有价值的，可探索和改进的内容也很多。相关数据集上已经出现了对bert进行修改后的复合模型，如squad2.0上哈工大(HIT)的<code>AoA + DA + BERT</code>以及西湖大学（DAMO）的<code>SLQA + BERT</code>。<br>在感谢google这份付出的同时，我们也可以借此站在巨人的肩膀上，尝试将其运用在自然语言处理领域的方方面面，让人工智能的梦想更近一步。</p>
<h2 id="声明"><a href="#声明" class="headerlink" title="声明"></a>声明</h2><p>本文相关工作在<a href="https://naturali.io/" target="_blank" rel="noopener">©奇点机智</a>工作期间完成，已授权<a href="https://naturali.io/" target="_blank" rel="noopener">©奇点机智</a>对文章的各类使用。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="default">
    <link itemprop="mainEntityOfPage" href="https://www.wendellsun.com/2018/10/12/用Graphs的运行方式执行Eager模式的代码/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Wendell Sun">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="宋竹温 | 不羁跬步">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2018/10/12/用Graphs的运行方式执行Eager模式的代码/" class="post-title-link" itemprop="url">用Graphs的运行方式执行Eager模式的代码</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-10-12 00:00:00" itemprop="dateCreated datePublished" datetime="2018-10-12T00:00:00+08:00">2018-10-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-12-24 19:43:36" itemprop="dateModified" datetime="2019-12-24T19:43:36+08:00">2019-12-24</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>一、在执行代码时使用 <code>tf.enable_eager_execution()</code> 开启eager模式</p>
<p>二、正向传播支持自定义class类型  </p>
<ol>
<li><a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/examples/rnn_ptb/rnn_ptb.py#L99" target="_blank" rel="noopener">定义</a>的model继承keras.model<br></li>
<li>在<a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/examples/rnn_ptb/rnn_ptb.py#L110" target="_blank" rel="noopener"><strong>init</strong>()</a>里定义所用到的layer类型<br></li>
<li>在<a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/examples/rnn_ptb/rnn_ptb.py#L133" target="_blank" rel="noopener">call()</a>里连接layer，返回<a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/examples/rnn_ptb/rnn_ptb.py#L146" target="_blank" rel="noopener">output</a><br></li>
</ol>
<p>二、反向传播的使用  </p>
<ol>
<li><p>先用tf的api定义<a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/examples/rnn_ptb/rnn_ptb.py#L158" target="_blank" rel="noopener">loss函数</a><br></p>
</li>
<li><p>用tfe的<a href="https://www.tensorflow.org/api_docs/python/tf/contrib/eager/implicit_gradients" target="_blank" rel="noopener">api</a>调用loss得到梯度grads  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tfe.gradients_function(loss,x)</span><br><span class="line">tfe.implicit_gradients(loss)</span><br></pre></td></tr></table></figure>

<p>或者也可以采用<a href="https://www.tensorflow.org/api_docs/python/tf/GradientTape" target="_blank" rel="noopener">GradientTape(y,x)</a>来进行计算可以根据函数y计算变量x的梯  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> grad_tape:</span><br><span class="line">    grad_tape.gradient(y,x)</span><br></pre></td></tr></table></figure>

<p>在tf的诸多eager execution样例中里用第二种方法较多  </p>
</li>
<li><p>用tf定义的<a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/examples/rnn_ptb/rnn_ptb.py#L317" target="_blank" rel="noopener">optimizer</a>优化梯度更新参数  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">optimizer.apply_gradients(grad)</span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>三、Eager的输入使用<code>tf.data.Dataset</code>但不支持<code>placeholder</code>和<code>string_input_producer</code>这类在graph模式中使用的输入</p>
<p>四、使用<code>tf.train.Checkpoint()</code><a href="https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint" target="_blank" rel="noopener">保存</a>模型的checkpoint</p>
<p>五、可以使用<code>tf.contrib.eager.defun</code>对python的函数进行封装转换成图的形式进行运算。用eager的写法可以实现graph的运算速度。  </p>
<ol>
<li><p>使用了defun的forward propagation例子如下:  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model.call = tf.contrib.eager.defun(model.call)</span><br><span class="line">model(x, training=<span class="literal">True</span>)  <span class="comment"># executes a graph, with dropout</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>一个使用了defun的back propagation例子如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">optimizer = tf.train.GradientDescentOptimizer()</span><br><span class="line"><span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">    outputs = model(x)</span><br><span class="line">gradient = tape.gradient(outputs, model.trainable_variables)</span><br><span class="line">defun_gradients = tfe.defun(gradient)</span><br><span class="line">tfe.defun(optimizer.apply_gradients((grad, var) <span class="keyword">for</span> grad, </span><br><span class="line">                var <span class="keyword">in</span> zip(gradient,model.trainable_variables)))</span><br></pre></td></tr></table></figure>

<p>然而此后<a href="https://www.tensorflow.org/api_docs/python/tf/contrib/eager/defun" target="_blank" rel="noopener">defun</a>可能会被<a href="https://medium.com/tensorflow/autograph-converts-python-into-tensorflow-graphs-b2a871f87ec7" target="_blank" rel="noopener">AutoGraph</a>替代</p>
</li>
</ol>
<p>Refer:<a href="https://medium.com/tensorflow/code-with-eager-execution-run-with-graphs-optimizing-your-code-with-revnet-as-an-example-6162333f9b08?linkId=55410234" target="_blank" rel="noopener">Code with Eager Execution, Run with Graphs: Optimizing Your Code with RevNet as an Example</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="default">
    <link itemprop="mainEntityOfPage" href="https://www.wendellsun.com/2018/09/21/checkpoint增加一些可阅读性的操作/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Wendell Sun">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="宋竹温 | 不羁跬步">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2018/09/21/checkpoint增加一些可阅读性的操作/" class="post-title-link" itemprop="url">checkpoint增加一些可阅读性的操作</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-09-21 00:00:00" itemprop="dateCreated datePublished" datetime="2018-09-21T00:00:00+08:00">2018-09-21</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-12-24 19:43:36" itemprop="dateModified" datetime="2019-12-24T19:43:36+08:00">2019-12-24</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="checkpoint增加一些可阅读性的操作"><a href="#checkpoint增加一些可阅读性的操作" class="headerlink" title="checkpoint增加一些可阅读性的操作"></a>checkpoint增加一些可阅读性的操作</h3><p>checkpoint的基础使用在官方的<a href="https://www.tensorflow.org/guide/saved_model" target="_blank" rel="noopener">手册</a>里描述地比较清楚了。但在进行迁移学习时，需要对一些预训练的权重进行读取，因此如果能可阅读得打印一些变量，可以使得读取过程变得简捷便利。</p>
<h4 id="checkpoint里变量名和权重值"><a href="#checkpoint里变量名和权重值" class="headerlink" title="checkpoint里变量名和权重值"></a>checkpoint里变量名和权重值</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.python <span class="keyword">import</span> pywrap_tensorflow</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">model_dir = <span class="string">'dir'</span></span><br><span class="line">file_name = <span class="string">'ckptfile'</span></span><br><span class="line"></span><br><span class="line">checkpoint_path = os.path.join(model_dir,file_name)</span><br><span class="line">reader = pywrap_tensorflow.NewCheckpointReader(checkpoint_path)</span><br><span class="line">var_to_shape_map = reader.get_variable_to_shape_map()</span><br><span class="line"><span class="keyword">for</span> key <span class="keyword">in</span> var_to_shape_map:</span><br><span class="line">    print(<span class="string">'tensor_name: '</span>,key) <span class="comment">#变量名</span></span><br><span class="line">    print(reader.get_tensor(key)) <span class="comment">#变量值</span></span><br></pre></td></tr></table></figure>

<p>在ckpt文件里的变量有两类，一类是进行前馈的权重，另一类是在后馈时的梯度。同时有一些变量并不是此前在构建模型时声明的，而是在实现各类模型api时自动产生的，通常这类变量会根据参数产生W和bias。对于包含多步线性计算的cell即各类RNN的cell而言，W会被整合成一个名为kernel的变量，其tensor大小将根据具体的计算方式生成，如lstm的kernel变量大小为(input_dim+lstm_dim,4*lstm_dim)。</p>
<h4 id="sess里变量读取预训练权重"><a href="#sess里变量读取预训练权重" class="headerlink" title="sess里变量读取预训练权重"></a>sess里变量读取预训练权重</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sess.run(tf.global_variables_initializer())</span><br><span class="line">sess.run(tf.local_variables_initializer())</span><br><span class="line">print_variable = [var.name <span class="keyword">for</span> var <span class="keyword">in</span> tf.global_variables()]</span><br><span class="line">print(print_variable)</span><br></pre></td></tr></table></figure>

<p>因为ckpt读取变量需要新变量和ckpt里的变量名字完全一致，所以可以通过上述代码查看变量名是否满足条件。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">variables_to_restore = [var <span class="keyword">for</span> var <span class="keyword">in</span> tf.global_variables()</span><br><span class="line">    <span class="keyword">if</span> var.name==<span class="string">'bias:0'</span> <span class="keyword">or</span> var.name==<span class="string">'kernel:0'</span>]</span><br><span class="line">saver = tf.train.Saver(variables_to_restore)</span><br><span class="line">model_dir = <span class="string">'dir'</span></span><br><span class="line">file_name = <span class="string">'ckptfile'</span></span><br><span class="line">checkpoint_path = os.path.join(model_dir,file_name)</span><br><span class="line">saver.restore(self.sess,checkpoint_path)</span><br></pre></td></tr></table></figure>

<p>通过在saver初始化时传入需要读取的参数，可以控制restore哪些变量。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="default">
    <link itemprop="mainEntityOfPage" href="https://www.wendellsun.com/2018/09/13/estimator的简单使用方式/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Wendell Sun">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="宋竹温 | 不羁跬步">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2018/09/13/estimator的简单使用方式/" class="post-title-link" itemprop="url">estimator的简单使用方式</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-09-13 00:00:00" itemprop="dateCreated datePublished" datetime="2018-09-13T00:00:00+08:00">2018-09-13</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-12-24 19:43:36" itemprop="dateModified" datetime="2019-12-24T19:43:36+08:00">2019-12-24</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="estimator的简单使用方式"><a href="#estimator的简单使用方式" class="headerlink" title="estimator的简单使用方式"></a>estimator的简单使用方式</h3><p><a href="https://www.tensorflow.org/programmers_guide/estimators?hl=zh-cn" target="_blank" rel="noopener">estimator</a>的官方使用方式介绍了使用自定义的estimator的model，没有涉及到从keras的model来使用estimator。<br>主要的使用方式来自这篇<a href="https://github.com/kashif/tf-keras-tutorial/blob/master/7-estimators-multi-gpus.ipynb" target="_blank" rel="noopener">notebook</a>在使用的时候没有遇上太多障碍。<br>但有一些细节花了一点时间去调试。<br>比如estimator能按照dataset重复次数<code>dataset.repeat(n)</code>作为epoch，因此如果直接使用<code>dataset.repeat()</code>会在训练时陷入死循环。</p>
<h4 id="model-fn的处理"><a href="#model-fn的处理" class="headerlink" title="model_fn的处理"></a>model_fn的处理</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model_fn</span><span class="params">(features, labels, mode)</span>:</span></span><br><span class="line">    keras_estimator_obj = tf.keras.estimator.model_to_estimator(</span><br><span class="line">        keras_model=base_model,</span><br><span class="line">        model_dir=&lt;model_dir&gt;,</span><br><span class="line">        config=&lt;run_config&gt;,</span><br><span class="line">    ) </span><br><span class="line"></span><br><span class="line">    <span class="comment"># pull model_fn that we need (hack)</span></span><br><span class="line">    <span class="keyword">return</span> keras_estimator_obj._model_fn</span><br></pre></td></tr></table></figure>

<p>通过传递参数是无法打印更多的训练结果，但是可以通过创建一个logging hook来让estimator运行。<br>In the body of model_fn function for your estimator:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">logging_hook = tf.train.LoggingTensorHook(&#123;<span class="string">"loss"</span> : loss, </span><br><span class="line">    <span class="string">"accuracy"</span> : accuracy&#125;, every_n_iter=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Rest of the function</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> tf.estimator.EstimatorSpec(</span><br><span class="line">    ...params...</span><br><span class="line">    training_hooks = [logging_hook])</span><br></pre></td></tr></table></figure>

<p>除了<code>self.estimator.train()</code>以外,可以使用<code>tf.estimator.train_and_evaluate()</code>对<code>train</code>和<code>evaluate</code>进行更精细地操作。  </p>
<p>此外<code>add_metrics(estimator,my_auc)</code>只是把metrics加入到最终结果的输出里，而不是每一次step，对于每一次step需要在<code>EstimatorSpec(training_hook=[logging_hook])</code>里添加logging_hook</p>
<p>多gpu出现的<br>All hooks must be SessionRunHook instances问题在<a href="https://github.com/tensorflow/tensorflow/issues/21444" target="_blank" rel="noopener">#issues21444</a> 里解决，等待tf-1.11版本。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="default">
    <link itemprop="mainEntityOfPage" href="https://www.wendellsun.com/2018/09/02/在keras中使用tf-dataset作为输入/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Wendell Sun">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="宋竹温 | 不羁跬步">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2018/09/02/在keras中使用tf-dataset作为输入/" class="post-title-link" itemprop="url">在keras中使用tf.dataset作为输入</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-09-02 00:00:00" itemprop="dateCreated datePublished" datetime="2018-09-02T00:00:00+08:00">2018-09-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-12-24 19:43:36" itemprop="dateModified" datetime="2019-12-24T19:43:36+08:00">2019-12-24</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="在keras中使用tf-dataset作为输入"><a href="#在keras中使用tf-dataset作为输入" class="headerlink" title="在keras中使用tf.dataset作为输入"></a>在keras中使用tf.dataset作为输入</h1><p>tf.dataset的API支持keras，是Tensorflow-1.9.0的一个新特性。使用tf.dataset作为输入的pipeline可以减少系统内存和显存的占用率，使得在训练大规模数据时，避免内存容量不够的问题出现。</p>
<p>在tensorflow的官方文档中，有简单的<a href="https://www.tensorflow.org/guide/keras" target="_blank" rel="noopener">使用说明</a>，但仍有一些<a href="https://github.com/tensorflow/tensorflow/issues/20827" target="_blank" rel="noopener">bug</a>在tensorflow-1.10.0中才将被修复。针对这个版本尚存在的一些问题，以下介绍一些可以规避这些问题的使用办法。</p>
<p>将tf.dataset作为输入传入可以在fit()函数中，也可以在Input()层和compiler()函数中分别<a href="https://stackoverflow.com/questions/46135499/how-to-properly-combine-tensorflows-dataset-api-and-keras" target="_blank" rel="noopener">传入</a>。<br> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#在fit()函数传入</span></span><br><span class="line">model.fit(x=iter_x.get_next(),y=iter_y.get_next(),</span><br><span class="line">          epochs=epochs,steps_per_epoch=steps_per_epoch)</span><br><span class="line"><span class="comment"># 在Input()层和compiler()函数传入</span></span><br><span class="line">inputs = Input(tensor=iter_x.get_next())</span><br><span class="line">model.compile(loss=loss,optimizer=optimizer,</span><br><span class="line">              target_tensors=[iter_y.get_next()])</span><br></pre></td></tr></table></figure></p>
<p>传入时需要将dataset类转换为tensor类。这一步涉及两个步骤，首先需要生成dataset的iterator,对于不同的dataset有不同生成方法，常用的有make_one_shot_iterator和make_initializable_iterator两种。之后通过iterator的get_next()函数迭代获取tensor类数据。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">iterator = dataset.make_initializable_iterator()</span><br><span class="line">iterator = dataset.make_one_shot_iterator()</span><br><span class="line">iterator = iterator.get_next()</span><br></pre></td></tr></table></figure>

<p>keras对于传入的tensor有tf.dtype的要求，x需要是tf.float32类型。如果类型不符，可以通过tf.cast()进行类型转换</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">inputs = Input(tensor=tf.cast(iter_x.get_next(),tf.float32))</span><br></pre></td></tr></table></figure>

<p>面对一系列初始化的需要时，可以先获取kera的session，并在keras的session中对table和iterator进行初始化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line">K.get_session().run(tf.tables_initializer())</span><br><span class="line">K.get_session().run(iter_data.initializer)</span><br></pre></td></tr></table></figure>

<p>训练时如果采用在Input()层和compiler()函数中传入x和y的方法，后续进行交叉验证、测试集测试以及结果生成时需要构建新的模型。因为这种方式相当于将模型的输入输出固定，将使模型不受输入输出的影响。新构建的模型需要符合原来模型的结构，但在Input()层和compiler()函数中的相应参数可以改为新的x和y。再传入训练时模型的权重并调用evaluate或者predict进行验证和预测。一个kears官方的<a href="https://github.com/keras-team/keras/blob/master/examples/mnist_dataset_api.py" target="_blank" rel="noopener">示例</a><br>如果在notebook中使用这种方法需要注意在内存中清除原来的会话。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">K.clear_session()</span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="default">
    <link itemprop="mainEntityOfPage" href="https://www.wendellsun.com/2018/08/29/将keras模型存成protobuf的格式/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Wendell Sun">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="宋竹温 | 不羁跬步">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2018/08/29/将keras模型存成protobuf的格式/" class="post-title-link" itemprop="url">将keras模型存成protobuf的格式</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-08-29 00:00:00" itemprop="dateCreated datePublished" datetime="2018-08-29T00:00:00+08:00">2018-08-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-12-24 19:43:36" itemprop="dateModified" datetime="2019-12-24T19:43:36+08:00">2019-12-24</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="将keras模型存成protobuf的格式"><a href="#将keras模型存成protobuf的格式" class="headerlink" title="将keras模型存成protobuf的格式"></a>将keras模型存成protobuf的格式</h3><p>tensorflow 有许多种不同的模型存储<a href="https://zhuanlan.zhihu.com/p/34471266" target="_blank" rel="noopener">格式</a>,不同的存储方式调用的存储函数是不一样的，使用tensorflow作为后端的keras也同样支持这些模型保存的方法。这里介绍一种能够方便部署在服务器端和移动端的<a href="https://developers.google.com/protocol-buffers/" target="_blank" rel="noopener">protobuf</a>格式。<br>建议采用<code>from tensorflow import keras</code>以及<code>from tensorflow.python.keras.models import...</code>来使用keras。<br>在构建好keras的网络结构后就可以开始对模型进行保存。为了使之后能便捷找到模型的结点，可以构建模型时对每一层的name参数进行赋值，对相关层命名。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">context_input = Input(shape=(<span class="number">10</span>,),name=<span class="string">'context_input'</span>)</span><br><span class="line">out = Dense((<span class="number">1</span>), activation = <span class="string">"sigmoid"</span>,name=<span class="string">"out"</span>)</span><br></pre></td></tr></table></figure>

<p>构建完模型后可以获得模型在tensorflow下的graph，查看网络结构是否如愿搭建以及此前命名是否成功。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">graph = K.get_session().graph</span><br><span class="line">K.set_learning_phase(<span class="number">0</span>)</span><br><span class="line"><span class="keyword">for</span> op <span class="keyword">in</span> graph.get_operations():</span><br><span class="line">    print(op.name)</span><br></pre></td></tr></table></figure>

<p>模型在保存前，可以通过<code>K.set_learning_phase(0)</code>将模型的参数设为不可变化的非训练模式。<br>模型的保存可以采用SaveModel的API进行保存，保存的结果将得到一个目录，目录里包含模型结构的pb文件以及包含参数名称和值的另一个目录。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.python.keras.models <span class="keyword">import</span> Model</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">export_path = <span class="string">'./keras_save'</span></span><br><span class="line">signature = tf.saved_model.signature_def_utils.predict_signature_def(</span><br><span class="line">    inputs=&#123;<span class="string">'sentence_name'</span>: dual_encoder.input&#125;, <span class="comment">#没有太明白signature的作用 #TODO</span></span><br><span class="line">    outputs=&#123;<span class="string">'outputs_name'</span>: dual_encoder.output&#125;)</span><br><span class="line">builder = tf.saved_model.builder.SavedModelBuilder(export_path)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> K.get_session() <span class="keyword">as</span> sess:</span><br><span class="line">    builder.add_meta_graph_and_variables(</span><br><span class="line">                sess,[<span class="string">'eval'</span>],</span><br><span class="line">                signature_def_map=&#123;<span class="string">'predict'</span>: signature&#125;)</span><br><span class="line">    builder.save(<span class="literal">True</span>)</span><br><span class="line">print(<span class="string">'Finished export'</span>, export_path)</span><br></pre></td></tr></table></figure>

<p>其中add_meta_graph_and_variables的第二个参数是<a href="https://www.tensorflow.org/api_docs/python/tf/saved_model/builder/SavedModelBuilder" target="_blank" rel="noopener">可选字符</a>。<br>虽然保存之后目录里有.pb文件，但这个.pb文件的格式并不能通过<code>graph_def.ParseFromString(f.read())</code>的方式进行读入，因为tensorflow的文件读写需要完全使用成对的api进行完成。对应于<code>f.saved_model.builder.SavedModelBuilder()</code>的是<code>tf.saved_model.loader.load()</code>具体的使用方式如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session(graph=tf.Graph()) <span class="keyword">as</span> sess:</span><br><span class="line">    tf.saved_model.loader.load(sess, [<span class="string">'eval'</span>], pb_file_path+<span class="string">'keras_save'</span>)</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    input_x1 = sess.graph.get_tensor_by_name(<span class="string">'context_input:0'</span>)</span><br><span class="line">    output_y = sess.graph.get_tensor_by_name(<span class="string">'out/Sigmoid:0'</span>) </span><br><span class="line">                                        <span class="comment">#其实是有更好的办法读预测结构 #TODO</span></span><br><span class="line">    ret = sess.run(output_y,feed_dict=&#123;input_x1:data1&#125;)</span><br></pre></td></tr></table></figure>

<p>这样<code>ret</code>得到的值便是对应输入<code>data1</code>的模型前馈的结果。<br>这部分有两个比较耗时的地方，首先是在load部分，其次是在get_tensor_by_name部分。因此在实际部署时，可以保持sess处于常开状态来减小i/o开销。此外，每个sess第一次run的时间将为之后run时间的数十倍。</p>
<h4 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h4><ul>
<li><a href="https://www.tensorflow.org/guide/graphs" target="_blank" rel="noopener">Tensorflow-Guide Graphs and Sessions</a></li>
<li><a href="https://medium.com/@johnsondsouza23/export-keras-model-to-protobuf-for-tensorflow-serving-101ad6c65142" target="_blank" rel="noopener">Export Keras Model to ProtoBuf for Tensorflow Serving</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/34471266" target="_blank" rel="noopener">我们给你推荐一种TensorFlow模型格式</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/29374467" target="_blank" rel="noopener">Tensorflow 1.13 Serving搭建心得on Docker（三）把keras或tf model改写成serving格式</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/32887066" target="_blank" rel="noopener">TensorFlow 保存模型为 PB 文件</a></li>
<li><a href="https://github.com/metaflow-ai/blog/tree/master/tf-freeze" target="_blank" rel="noopener">metaflow-ai/blog</a></li>
<li><a href="https://blog.metaflow.fr/tensorflow-how-to-freeze-a-model-and-serve-it-with-a-python-api-d4f3596b3adc" target="_blank" rel="noopener">TensorFlow: How to freeze a model and serve it with a python API</a></li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

  </div>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Wendell Sun</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.9.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://muse.theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> v7.6.0
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script>
<script src="/js/schemes/muse.js"></script>
<script src="/js/next-boot.js"></script>



  




  <script src="/js/local-search.js"></script>












  

  


</body>
</html>
