<!DOCTYPE html>
<html lang="">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 3.9.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-wendellsun.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/wendellsun_32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/wendellsun_16x16.png.png">
  <link rel="mask-icon" href="/images/wendellsun_logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('https://www.wendellsun.com').hostname,
    root: '/',
    scheme: 'Muse',
    version: '7.6.0',
    exturl: false,
    sidebar: {"position":"left","display":"remove","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    comments: {"style":"tabs","active":"gitalk","storage":true,"lazyload":false,"nav":{"gitalk":{"order":-2}},"activeClass":"gitalk"},
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":3,"unescape":false,"preload":false},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}
  };
</script>

  <meta name="description" content="从11月初开始，google-research就陆续开源了bert的各个版本。google此次开源的bert是通过tensorflow高级API—— tf.estimator进行封装(wrapper)的。因此对于不同数据集的适配，只需要修改代码中的processor部分，就能进行代码的训练、交叉验证和测试。 在自己的数据集上运行bertbert的代码同论文里描述的一致，主要分为两个部分。一个是训练">
<meta property="og:type" content="article">
<meta property="og:title" content="Bert FineTune 实践">
<meta property="og:url" content="https://www.wendellsun.com/2018/11/23/Bert-FineTune-实践/index.html">
<meta property="og:site_name" content="宋竹温 | 不羁跬步">
<meta property="og:description" content="从11月初开始，google-research就陆续开源了bert的各个版本。google此次开源的bert是通过tensorflow高级API—— tf.estimator进行封装(wrapper)的。因此对于不同数据集的适配，只需要修改代码中的processor部分，就能进行代码的训练、交叉验证和测试。 在自己的数据集上运行bertbert的代码同论文里描述的一致，主要分为两个部分。一个是训练">
<meta property="og:locale" content="default">
<meta property="og:updated_time" content="2019-12-24T11:43:36.001Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Bert FineTune 实践">
<meta name="twitter:description" content="从11月初开始，google-research就陆续开源了bert的各个版本。google此次开源的bert是通过tensorflow高级API—— tf.estimator进行封装(wrapper)的。因此对于不同数据集的适配，只需要修改代码中的processor部分，就能进行代码的训练、交叉验证和测试。 在自己的数据集上运行bertbert的代码同论文里描述的一致，主要分为两个部分。一个是训练">

<link rel="canonical" href="https://www.wendellsun.com/2018/11/23/Bert-FineTune-实践/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true
  };
</script>

  <title>Bert FineTune 实践 | 宋竹温 | 不羁跬步</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">宋竹温 | 不羁跬步</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">工人有力量，硅器有生命</p>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-rss">

    <a href="/rss2.xml" rel="section"><i class="fa fa-fw fa-rss"></i>Rss</a>

  </li>
        <li class="menu-item menu-item-router">

    <a href="/2020/03/31/尝无止尽路由/index.html" rel="section"><i class="fa fa-fw fa-sitemap"></i>Router</a>

  </li>
        <li class="menu-item menu-item-cinema">

    <a href="http://wendellsun.live/" rel="noopener" target="_blank"><i class="fa fa-fw fa-film"></i>Cinema</a>

  </li>
        <li class="menu-item menu-item-castecho">

    <a href="https://www.castecho.com/" rel="noopener" target="_blank"><i class="fa fa-fw fa-bullseye"></i>CastEcho</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="Searching..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="default">
    <link itemprop="mainEntityOfPage" href="https://www.wendellsun.com/2018/11/23/Bert-FineTune-实践/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Wendell Sun">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="宋竹温 | 不羁跬步">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Bert FineTune 实践
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-11-23 00:00:00" itemprop="dateCreated datePublished" datetime="2018-11-23T00:00:00+08:00">2018-11-23</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-12-24 19:43:36" itemprop="dateModified" datetime="2019-12-24T19:43:36+08:00">2019-12-24</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>从11月初开始，<a href="https://github.com/google-research" target="_blank" rel="noopener">google-research</a>就陆续开源了<a href="https://github.com/google-research/bert" target="_blank" rel="noopener">bert</a>的各个版本。google此次开源的bert是通过tensorflow高级API—— <code>tf.estimator</code>进行封装(wrapper)的。因此对于不同数据集的适配，只需要修改代码中的processor部分，就能进行代码的训练、交叉验证和测试。</p>
<h2 id="在自己的数据集上运行bert"><a href="#在自己的数据集上运行bert" class="headerlink" title="在自己的数据集上运行bert"></a>在自己的数据集上运行bert</h2><p>bert的代码同论文里描述的一致，主要分为两个部分。一个是训练语言模型（language model）的预训练（pretrain）部分。另一个是训练具体任务(task)的fine-tune部分。在开源的代码中，预训练的入口是在<code>run_pretraining.py</code>而fine-tune的入口针对不同的任务分别在<code>run_classifier.py</code>和<code>run_squad.py</code>。其中<code>run_classifier.py</code>适用的任务为分类任务。如CoLA、MRPC、MultiNLI这些数据集。而<code>run_squad.py</code>适用的是阅读理解(MRC)任务，如squad2.0和squad1.1。预训练是bert很重要的一个部分，与此同时，预训练需要巨大的运算资源。按照论文里描述的参数，其Base的设定在消费级的显卡Titan x 或Titan 1080ti(12GB RAM)上，甚至需要近几个月的时间进行预训练，同时还会面临显存不足的问题。不过所幸的是谷歌满足了<a href="https://github.com/google-research/bert/issues/2" target="_blank" rel="noopener">issues#2</a>里各国开发者的请求，针对大部分语言都公布了bert的<a href="https://github.com/google-research/bert/blob/master/multilingual.md" target="_blank" rel="noopener">预训练模型</a>。因此在我们可以比较方便得在自己的数据集上进行fine-tune。</p>
<h3 id="下载预训练模型"><a href="#下载预训练模型" class="headerlink" title="下载预训练模型"></a>下载预训练模型</h3><p>对于中文而言，google公布了一个参数较小的bert预训练模型。具体参数数值如下所示：</p>
<blockquote>
<p>Chinese Simplified and Traditional, 12-layer, 768-hidden, 12-heads, 110M parameters  </p>
</blockquote>
<p>模型的<a href="https://storage.googleapis.com/bert_models/2018_11_03/chinese_L-12_H-768_A-12.zip" target="_blank" rel="noopener">下载链接</a>可以在github上google的开源代码里找到。对下载的压缩文件进行解压，可以看到文件里有五个文件，其中bert_model.ckpt开头的文件是负责模型变量载入的，而vocab.txt是训练时中文文本采用的字典，最后bert_config.json是bert在训练时，可选调整的一些参数。</p>
<h3 id="修改processor"><a href="#修改processor" class="headerlink" title="修改processor"></a>修改processor</h3><p>任何模型的训练、预测都是需要有一个明确的输入，而bert代码中processor就是负责对模型的输入进行处理。我们以分类任务的为例，介绍如何修改processor来运行自己数据集上的fine-tune。在<code>run_classsifier.py</code>文件中我们可以看到，google对于一些公开数据集已经写了一些processor，如<code>XnliProcessor</code>,<code>MnliProcessor</code>,<code>MrpcProcessor</code>和<code>ColaProcessor</code>。这给我们提供了一个很好的示例，指导我们如何针对自己的数据集来写processor。<br>对于一个需要执行训练、交叉验证和测试完整过程的模型而言，自定义的processor里需要继承DataProcessor，并重载获取label的<code>get_labels</code>和获取单个输入的<code>get_train_examples</code>,<code>get_dev_examples</code>和<code>get_test_examples</code>函数。其分别会在<code>main</code>函数的<code>FLAGS.do_train</code>、<code>FLAGS.do_eval</code>和<code>FLAGS.do_predict</code>阶段被调用。<br>这三个函数的内容是相差无几的，区别只在于需要指定各自读入文件的地址。以<code>get_train_examples</code>为例，函数需要返回一个由<code>InputExample</code>类组成的<code>list</code>。<code>InputExample</code>类是一个很简单的类，只有初始化函数，需要传入的参数中guid是用来区分每个example的，可以按照<code>train-%d&#39;%(i)</code>的方式进行定义。text_a是一串字符串，text_b则是另一串字符串。在进行后续输入处理后(bert代码中已包含，不需要自己完成) text_a和text_b将组合成<code>[CLS] text_a [SEP] text_b [SEP]</code>的形式传入模型。最后一个参数label也是字符串的形式，label的内容需要保证出现在<code>get_labels</code>函数返回的<code>list</code>里。<br>举一个例子，假设我们想要处理一个能够判断句子相似度的模型，现在在<code>data_dir</code>的路径下有一个名为<code>train.csv</code>的输入文件，如果我们现在输入文件的格式如下csv形式：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1,你好,您好</span><br><span class="line">0,你好,你家住哪</span><br></pre></td></tr></table></figure>

<p>那么我们可以写一个如下的<code>get_train_examples</code>的函数。当然对于csv的处理，可以使用诸如<code>csv.reader</code>的形式进行读入。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_train_examples</span><span class="params">(self, data_dir)</span>：</span></span><br><span class="line">    file_path = os.path.join(data_dir, 'train.csv')</span><br><span class="line">    <span class="keyword">with</span> open(file_path, <span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        reader = f.readlines()</span><br><span class="line">    examples = []</span><br><span class="line">    <span class="keyword">for</span> index, line <span class="keyword">in</span> enumerate(reader):</span><br><span class="line">        guid = <span class="string">'train-%d'</span>%index</span><br><span class="line">        split_line = line.strip().split(<span class="string">','</span>)</span><br><span class="line">        text_a = tokenization.convert_to_unicode(split_line[<span class="number">1</span>])</span><br><span class="line">        text_b = tokenization.convert_to_unicode(split_line[<span class="number">2</span>])</span><br><span class="line">        label = split_line[<span class="number">0</span>]</span><br><span class="line">        examples.append(InputExample(guid=guid, text_a=text_a,</span><br><span class="line">                                        text_b=text_b, label=label))</span><br><span class="line">    <span class="keyword">return</span> examples</span><br></pre></td></tr></table></figure>

<p>同时对应判断句子相似度这个二分类任务，<code>get_labels</code>函数可以写成如下的形式：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_labels</span><span class="params">(self)</span>:</span></span><br><span class="line">    reutrn [<span class="string">'0'</span>,<span class="string">'1'</span>]</span><br></pre></td></tr></table></figure>

<p>在对<code>get_dev_examples</code>和<code>get_test_examples</code>函数做类似<code>get_train_examples</code>的操作后，便完成了对processor的修改。其中<code>get_test_examples</code>可以传入一个随意的label数值，因为在模型的预测（prediction）中label将不会参与计算。  </p>
<h3 id="修改processor字典"><a href="#修改processor字典" class="headerlink" title="修改processor字典"></a>修改processor字典</h3><p>修改完成processor后，需要在在原本<code>main</code>函数的processor字典里，加入修改后的processor类，即可在运行参数里指定调用该processor。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">processors = &#123;</span><br><span class="line">     <span class="string">"cola"</span>: ColaProcessor,</span><br><span class="line">     <span class="string">"mnli"</span>: MnliProcessor,</span><br><span class="line">     <span class="string">"mrpc"</span>: MrpcProcessor,</span><br><span class="line">     <span class="string">"xnli"</span>: XnliProcessor, </span><br><span class="line">     <span class="string">"selfsim"</span>: SelfProcessor <span class="comment">#添加自己的processor</span></span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>

<h3 id="运行fine-tune"><a href="#运行fine-tune" class="headerlink" title="运行fine-tune"></a>运行fine-tune</h3><p>之后就可以直接运行<code>run_classsifier.py</code>进行模型的训练。在运行时需要制定一些参数，一个较为完整的运行参数如下所示：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> BERT_BASE_DIR=/path/to/bert/chinese_L-12_H-768_A-12 <span class="comment">#全局变量 下载的预训练bert地址</span></span><br><span class="line"><span class="built_in">export</span> MY_DATASET=/path/to/xnli <span class="comment">#全局变量 数据集所在地址</span></span><br><span class="line"></span><br><span class="line">python run_classifier.py \</span><br><span class="line">  --task_name=selfsim \ <span class="comment">#自己添加processor在processors字典里的key名</span></span><br><span class="line">  --do_train=<span class="literal">true</span> \</span><br><span class="line">  --do_eval=<span class="literal">true</span> \</span><br><span class="line">  --dopredict=<span class="literal">true</span> \</span><br><span class="line">  --data_dir=<span class="variable">$MY_DATASET</span> \</span><br><span class="line">  --vocab_file=<span class="variable">$BERT_BASE_DIR</span>/vocab.txt \</span><br><span class="line">  --bert_config_file=<span class="variable">$BERT_BASE_DIR</span>/bert_config.json \</span><br><span class="line">  --init_checkpoint=<span class="variable">$BERT_BASE_DIR</span>/bert_model.ckpt \</span><br><span class="line">  --max_seq_length=128 \ <span class="comment">#模型参数</span></span><br><span class="line">  --train_batch_size=32 \</span><br><span class="line">  --learning_rate=5e-5 \</span><br><span class="line">  --num_train_epochs=2.0 \</span><br><span class="line">  --output_dir=/tmp/selfsim_output/ <span class="comment">#模型输出路径</span></span><br></pre></td></tr></table></figure>

<h2 id="bert源代码里还有什么"><a href="#bert源代码里还有什么" class="headerlink" title="bert源代码里还有什么"></a>bert源代码里还有什么</h2><p>在开始训练我们自己fine-tune的bert后，我们可以再来看看bert代码里除了processor之外的一些部分。<br>我们可以发现，process在得到字符串形式的输入后，在<code>file_based_convert_examples_to_features</code>里先是对字符串长度，加入[CLS]和[SEP]等一些处理后，将其写入成TFrecord的形式。这是为了能在estimator里有一个更为高效和简易的读入。<br>我们还可以发现，在<code>create_model</code>的函数里，除了从<code>modeling.py</code>获取模型主干输出之外，还有进行fine-tune时候的loss计算。因此，如果对于fine-tune的结构有自定义的要求，可以在这部分对代码进行修改。如进行NER任务的时候，可以按照bert论文里的方式，不只读第一位的logits，而是将每一位logits进行读取。<br>bert这次开源的代码，由于是考虑在google自己的TPU上高效地运行，因此采用的estimator是<code>tf.contrib.tpu.TPUEstimator</code>,虽然tpu的estimator同样可以在gpu和cpu上运行，但若想在gpu上更高效得做一些提升，可以考虑将其换成<code>tf.estimator.Estimator</code>,于此同时model_fn里一些<code>tf.contrib.tpu.TPUEstimatorSpec</code>也需要修改成<code>tf.estimator.EstimatorSpec</code>的形式，以及相关调用参数也需要做一些调整。在转换成较普通的estimator后便可以使用常用的方式对estimator进行处理，如生成用于部署的<code>.pb</code>文件等。</p>
<h2 id="issues里一些有趣的内容"><a href="#issues里一些有趣的内容" class="headerlink" title="issues里一些有趣的内容"></a>issues里一些有趣的内容</h2><p>从google对bert进行开源开始，issues里的讨论便异常活跃，bert论文第一作者javob devlin也积极地在issues里进行回应，在交流讨论中，产生了一些很有趣的内容。<br>在<a href="https://github.com/google-research/bert/issues/95" target="_blank" rel="noopener">#95</a>中大家讨论了bert模型在今年ai-challenger比赛上的应用。我们也同样尝试了bert在ai-challenger的mrc赛道的表现。如果简单得地将mrc的文本连接成一个长字符串的形式，可以在dev集上得到79.1%的准确率。如果参考openAI的GPT<a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf" target="_blank" rel="noopener">论文</a>里multi-choice的形式对bert的输入输出代码进行修改则可以将准确率提高到79.3%。采用的参数都是bert默认的参数，而单一模型成绩在赛道的test a排名中已经能超过榜单上的第一名。因此，在相关中文的任务中，bert能有很大的想象空间。<br>在<a href="https://github.com/google-research/bert/issues/123" target="_blank" rel="noopener">#123</a>中，<a href="https://github.com/hanxiao" target="_blank" rel="noopener">@hanxiao</a>给出了一个采用ZeroMQ便捷部署bert的service，可以直接调用训练好的模型作为应用的接口。同时他将bert改为一个大的encode模型，将文本通过bert进行encode，来实现句子级的encode。此外，他对比了多GPU上的性能，发现bert在多GPU并行上的出色表现。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>总得来说，google此次开源的bert和其预训练模型是非常有价值的，可探索和改进的内容也很多。相关数据集上已经出现了对bert进行修改后的复合模型，如squad2.0上哈工大(HIT)的<code>AoA + DA + BERT</code>以及西湖大学（DAMO）的<code>SLQA + BERT</code>。<br>在感谢google这份付出的同时，我们也可以借此站在巨人的肩膀上，尝试将其运用在自然语言处理领域的方方面面，让人工智能的梦想更近一步。</p>
<h2 id="声明"><a href="#声明" class="headerlink" title="声明"></a>声明</h2><p>本文相关工作在<a href="https://naturali.io/" target="_blank" rel="noopener">©奇点机智</a>工作期间完成，已授权<a href="https://naturali.io/" target="_blank" rel="noopener">©奇点机智</a>对文章的各类使用。</p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2018/10/12/用Graphs的运行方式执行Eager模式的代码/" rel="prev" title="用Graphs的运行方式执行Eager模式的代码">
      <i class="fa fa-chevron-left"></i> 用Graphs的运行方式执行Eager模式的代码
    </a></div>
      <div class="post-nav-item">
    <a href="/2019/07/02/「The-score」意外小众的流行摇滚组合/" rel="next" title="「The score」意外小众的流行摇滚组合">
      「The score」意外小众的流行摇滚组合 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          
    <div class="comments" id="gitalk-container"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Wendell Sun</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.9.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://muse.theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> v7.6.0
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script>
<script src="/js/schemes/muse.js"></script>
<script src="/js/next-boot.js"></script>



  




  <script src="/js/local-search.js"></script>












  

  

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">

<script>
NexT.utils.loadComments(document.querySelector('#gitalk-container'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID: '7835aa064fbc83c57c66',
      clientSecret: 'f025dcec53ffe435876bac77f897f444c5d188fd',
      repo: 'gitalk_on_wendellsun_blog',
      owner: 'PsYear',
      admin: ['PsYear'],
      id: '8b61503b6f02262e734d464f870d3d1c',
        language: 'zh-CN',
      distractionFreeMode: true
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});
</script>

</body>
</html>
